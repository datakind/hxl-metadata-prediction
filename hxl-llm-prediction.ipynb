{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook downloads data provided by the HDX team from a google drive folder. The data was captured using an [HXL crawl process](https://github.com/HXLStandard/hdx-hashtag-crawler)\n",
    "\n",
    "# Setup\n",
    "\n",
    "1. Install [miniconda](https://docs.conda.io/en/latest/miniconda.html) by selecting the installer that fits your OS version. Once it is installed you may have to restart your terminal (closing your terminal and opening again)\n",
    "2. In this directory, open terminal\n",
    "3. `conda env create -f environment.yml`\n",
    "4. `conda activate hxl-prediction` use this runtime to run this notebook \n",
    "5. Set `OPENAI_API_KEY` in `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gdown\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from hdx.utilities.easy_logging import setup_logging\n",
    "from hdx.api.configuration import Configuration\n",
    "from hdx.data.dataset import Dataset\n",
    "import hxl\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "input_options = hxl.input.InputOptions(http_headers={'User-Agent': \"DK HXL Analaysis\"})\n",
    "\n",
    "# Google drive location of HDXHashtag crawler data\n",
    "DATA_GDRIVE=\"https://drive.google.com/file/d/1BDCuh0WVJWK1-1RMC-77cvh4H2Hep_ry/view?usp=drive_link\"\n",
    "DATA_FILE=\"hdx-hxl-output.tgz\"\n",
    "\n",
    "# Where to save local data files\n",
    "LOCAL_DATA_DIR = \"./data/hdx-hxl\"\n",
    "\n",
    "# Number of records in data excerpts\n",
    "DATA_EXCERPT_SIZE = 10\n",
    "\n",
    "local_data_file = LOCAL_DATA_DIR + \"/\" + DATA_FILE + '/output/'\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_count = 0\n",
    "\n",
    "def setup_hdx_connection(agent_name):\n",
    "    try:\n",
    "        Configuration.create(hdx_site=\"prod\", user_agent=agent_name, hdx_read_only=True)\n",
    "    except:\n",
    "        print(\"Configuration already created, continuing ...\")\n",
    "\n",
    "# Note, if you run this twice you will get a 'Configuration already exists!' error, but it can be ignored \n",
    "setup_hdx_connection(f\"DK_UserAgent{agent_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "## Download HXL crawler data\n",
    "\n",
    "This data was generated using the [HDX Hashtag Crawler](https://github.com/dividor/hdx-hashtag-crawler) over several days and saved to Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1BDCuh0WVJWK1-1RMC-77cvh4H2Hep_ry\n",
      "To: /Users/matthewharris/Desktop/git/hxl_metadata_prediction/data/hdx-hxl/hdx-hxl-output.tgz\n",
      "100%|██████████| 19.3M/19.3M [00:01<00:00, 10.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Use gdown to download the file\n",
    "gdown.download(DATA_GDRIVE, local_data_file, quiet=False, fuzzy=True)\n",
    "\n",
    "tar = tarfile.open(local_data_file)\n",
    "tar.extractall(LOCAL_DATA_DIR)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Unique combinations of HXL tags we want for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6b/jxkmd4lx1nl8lc4sdpn0yz500000gn/T/ipykernel_29168/3428572768.py:3: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(LOCAL_DATA_DIR + \"/output/hdx-expanded-hashed-stats.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtag with Attributes</th>\n",
       "      <th>Text header</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Data provider</th>\n",
       "      <th>HDX dataset id</th>\n",
       "      <th>HDX resource id</th>\n",
       "      <th>Date created</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#affected+hh</td>\n",
       "      <td>Total IDP HH</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>true</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#affected+idp+ind</td>\n",
       "      <td>Total IDP IND</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>true</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#affected+idp+male</td>\n",
       "      <td>Total IDP Male Ind</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>true</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#affected+female+idp</td>\n",
       "      <td>Total IDP Female Ind</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>true</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#affected+ind+returnees</td>\n",
       "      <td>Total Returnees</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>true</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hashtag with Attributes           Text header Locations  \\\n",
       "1             #affected+hh          Total IDP HH       COD   \n",
       "2        #affected+idp+ind         Total IDP IND       COD   \n",
       "4       #affected+idp+male    Total IDP Male Ind       COD   \n",
       "6     #affected+female+idp  Total IDP Female Ind       COD   \n",
       "8  #affected+ind+returnees       Total Returnees       COD   \n",
       "\n",
       "                              Data provider  \\\n",
       "1  international-organization-for-migration   \n",
       "2  international-organization-for-migration   \n",
       "4  international-organization-for-migration   \n",
       "6  international-organization-for-migration   \n",
       "8  international-organization-for-migration   \n",
       "\n",
       "                                                                               HDX dataset id  \\\n",
       "1  drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "2  drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "4  drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "6  drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "8  drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "\n",
       "                        HDX resource id Date created Unnamed: 9  \\\n",
       "1  26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       true   \n",
       "2  26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       true   \n",
       "4  26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       true   \n",
       "6  26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       true   \n",
       "8  26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       true   \n",
       "\n",
       "                 Hash  \n",
       "1  0x2cc7fd3129c0d18c  \n",
       "2  0x2cc7fd3129c0d18c  \n",
       "4  0x2cc7fd3129c0d18c  \n",
       "6  0x2cc7fd3129c0d18c  \n",
       "8  0x2cc7fd3129c0d18c  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487297, 9)\n",
      "Unique data providers ...\n",
      "120\n",
      "Unique HDX resource ids ...\n",
      "43074\n"
     ]
    }
   ],
   "source": [
    "# Open hdx-expanded-hashed-stats.csv in data/hdx-hxl\n",
    "\n",
    "df = pd.read_csv(LOCAL_DATA_DIR + \"/output/hdx-expanded-hashed-stats.csv\")\n",
    "\n",
    "# We'll keep one row per column, Hashtag with Attributes has what we require\n",
    "df.drop(columns=['Attribute', 'Hashtag'], inplace=True)\n",
    "df.drop_duplicates(inplace=True)  \n",
    "\n",
    "# Remove HXL tags row in the metadata (we keep them for actual data)\n",
    "df = df[1:]\n",
    "\n",
    "display(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "print(\"Unique data providers ...\")\n",
    "print(len(df[\"Data provider\"].unique()))\n",
    "\n",
    "print(\"Unique HDX resource ids ...\")\n",
    "print(len(df[\"HDX resource id\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the column hash created by the crawler to find unique combinations of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hash\n",
       "0x100556db35012c6b       101\n",
       "0x102125f4dd16c64     190286\n",
       "0x10309a2e5e2722ba       509\n",
       "0x105b36aac3c9192f       693\n",
       "0x105c6ee3379af31c       595\n",
       "                       ...  \n",
       "0xf0a7e4d9104f069         12\n",
       "0xf93f0051e52a4d          28\n",
       "0xfa11ad9f842a37d         17\n",
       "0xfe0e278de9d0a33          1\n",
       "0xfe8777dcd878424         20\n",
       "Length: 644, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hash_count = df.groupby('Hash').size()\n",
    "display(hash_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Hash</th>\n",
       "      <th>HDX resource id</th>\n",
       "      <th>Unique HDX resource id</th>\n",
       "      <th>Unique HDX dataset id</th>\n",
       "      <th>Unique Data provider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0x102125f4dd16c64</td>\n",
       "      <td>13858</td>\n",
       "      <td>[51b2e4ec-aca5-4b97-bbb7-c005175b682e, a6ef8040-3b15-47ae-9973-1dbc113673cf, f579cf0e-5535-4414-897f-2f8c05105180, 66c62464-017b-4aa6-845f-9ec2487acb82, 91e1cb98-353b-487e-a14d-b0eea783da6f, 65f38...</td>\n",
       "      <td>[who-data-for-south-sudan, who-data-for-montenegro, who-data-for-zimbabwe, who-data-for-zambia, who-data-for-yemen, who-data-for-viet-nam, who-data-for-venezuela-bolivarian-republic-of, who-data-f...</td>\n",
       "      <td>[world-health-organization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0x428a8e37940223d8</td>\n",
       "      <td>9328</td>\n",
       "      <td>[2e130cdf-c850-4533-b2f3-e961adbec48a, 9e160d82-691d-49a6-979b-0ff0dbb6b7a8, 002501bc-7efb-4335-b672-d045cd76bc5b, 0d0e0fc4-e4f1-49cd-ad30-42cc8dc08b74, f2c1ea93-d241-413b-8140-c009da88d912, 23e36...</td>\n",
       "      <td>[world-bank-combined-indicators-for-zimbabwe, world-bank-trade-indicators-for-zimbabwe, world-bank-external-debt-indicators-for-zimbabwe, world-bank-climate-change-indicators-for-zimbabwe, world-b...</td>\n",
       "      <td>[world-bank-group]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0x31fda1ef985b4a59</td>\n",
       "      <td>3425</td>\n",
       "      <td>[9c751883-698a-4a2c-9475-ff828e9c11db, 791b69af-df57-4157-96c0-c0d8d308315e, b055f1f7-8cdc-4ff8-a412-9f54d6e56c41, 6ae8568f-449b-4b59-9ad2-79d7df94cd9c, 4f4c7462-6b13-4125-a88a-f8e9ac0c837b, abb79...</td>\n",
       "      <td>[dhs-data-for-sao-tome-and-principe, dhs-data-for-rwanda, dhs-data-for-philippines, dhs-data-for-peru, dhs-data-for-paraguay, dhs-data-for-papua-new-guinea, dhs-data-for-pakistan, dhs-data-for-nig...</td>\n",
       "      <td>[dhs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0x19598575d3397e19</td>\n",
       "      <td>3232</td>\n",
       "      <td>[ed7b5bd2-7818-4d7a-9ff0-8ba0d97bf7d5, 8f239e93-76c0-4287-a414-3d17a5e55344, 040efd19-3d71-4e0b-8939-f6b46c465868, 8db41d1c-af8f-4f26-9d40-5b80b1bf72e8, 6482dc75-0e79-40d9-aacf-cdcde3c368a6, c9981...</td>\n",
       "      <td>[dhs-subnational-data-for-sao-tome-and-principe, dhs-subnational-data-for-rwanda, dhs-subnational-data-for-philippines, dhs-subnational-data-for-peru, dhs-subnational-data-for-paraguay, dhs-subnat...</td>\n",
       "      <td>[dhs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0x16d2b679132fea10</td>\n",
       "      <td>2147</td>\n",
       "      <td>[295cd9e4-8464-43ee-ad17-47196991a1f7, 34337d16-017d-4d69-834c-a5e0fc21a549, b51b8c0e-494d-488b-98d5-a70fd9451b90, 75076d6a-8d3f-49e3-b4f4-7c889bc82806, 7e0b2b37-73b8-4c69-bb11-6ba954fa0cd9, 08ea0...</td>\n",
       "      <td>[unhcr-population-data-for-world, unhcr-population-data-for-zwe, unhcr-population-data-for-zmb, unhcr-population-data-for-zaf, unhcr-population-data-for-yem, unhcr-population-data-for-wsm, unhcr-p...</td>\n",
       "      <td>[unhcr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>0x22def8e1b7b0c742</td>\n",
       "      <td>1</td>\n",
       "      <td>[68328f42-9276-423e-80d0-fe89630804ff]</td>\n",
       "      <td>[3w-december-2017]</td>\n",
       "      <td>[ocha-ethiopia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>0x4b7012601f2de402</td>\n",
       "      <td>1</td>\n",
       "      <td>[63143067-46e0-4fb5-b131-d83ee45122ab]</td>\n",
       "      <td>[ethiopia-settlements]</td>\n",
       "      <td>[ocha-ethiopia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>641</td>\n",
       "      <td>641</td>\n",
       "      <td>0x4aefd35864aaa20a</td>\n",
       "      <td>1</td>\n",
       "      <td>[6ddcfbc9-fa06-4b14-b9a4-ce96d3fae65e]</td>\n",
       "      <td>[base-acceso-internet-personas-entre-los-5-y-19-anos-2018]</td>\n",
       "      <td>[immap]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>642</td>\n",
       "      <td>642</td>\n",
       "      <td>0x4acf4e36d67d877</td>\n",
       "      <td>1</td>\n",
       "      <td>[903326f2-b372-4786-9973-87226cb15e41]</td>\n",
       "      <td>[people-in-need-2008-2019]</td>\n",
       "      <td>[ocha-fts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>643</td>\n",
       "      <td>643</td>\n",
       "      <td>0x57297f722f5115a5</td>\n",
       "      <td>1</td>\n",
       "      <td>[8b0feea6-20e4-45dc-aaae-c8b6fbd5a9f4]</td>\n",
       "      <td>[burkina-faso-plan-d-urgence]</td>\n",
       "      <td>[ocha-rowca]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0  index                Hash  HDX resource id  \\\n",
       "0          0      0   0x102125f4dd16c64            13858   \n",
       "1          1      1  0x428a8e37940223d8             9328   \n",
       "2          2      2  0x31fda1ef985b4a59             3425   \n",
       "3          3      3  0x19598575d3397e19             3232   \n",
       "4          4      4  0x16d2b679132fea10             2147   \n",
       "..       ...    ...                 ...              ...   \n",
       "639      639    639  0x22def8e1b7b0c742                1   \n",
       "640      640    640  0x4b7012601f2de402                1   \n",
       "641      641    641  0x4aefd35864aaa20a                1   \n",
       "642      642    642   0x4acf4e36d67d877                1   \n",
       "643      643    643  0x57297f722f5115a5                1   \n",
       "\n",
       "                                                                                                                                                                                      Unique HDX resource id  \\\n",
       "0    [51b2e4ec-aca5-4b97-bbb7-c005175b682e, a6ef8040-3b15-47ae-9973-1dbc113673cf, f579cf0e-5535-4414-897f-2f8c05105180, 66c62464-017b-4aa6-845f-9ec2487acb82, 91e1cb98-353b-487e-a14d-b0eea783da6f, 65f38...   \n",
       "1    [2e130cdf-c850-4533-b2f3-e961adbec48a, 9e160d82-691d-49a6-979b-0ff0dbb6b7a8, 002501bc-7efb-4335-b672-d045cd76bc5b, 0d0e0fc4-e4f1-49cd-ad30-42cc8dc08b74, f2c1ea93-d241-413b-8140-c009da88d912, 23e36...   \n",
       "2    [9c751883-698a-4a2c-9475-ff828e9c11db, 791b69af-df57-4157-96c0-c0d8d308315e, b055f1f7-8cdc-4ff8-a412-9f54d6e56c41, 6ae8568f-449b-4b59-9ad2-79d7df94cd9c, 4f4c7462-6b13-4125-a88a-f8e9ac0c837b, abb79...   \n",
       "3    [ed7b5bd2-7818-4d7a-9ff0-8ba0d97bf7d5, 8f239e93-76c0-4287-a414-3d17a5e55344, 040efd19-3d71-4e0b-8939-f6b46c465868, 8db41d1c-af8f-4f26-9d40-5b80b1bf72e8, 6482dc75-0e79-40d9-aacf-cdcde3c368a6, c9981...   \n",
       "4    [295cd9e4-8464-43ee-ad17-47196991a1f7, 34337d16-017d-4d69-834c-a5e0fc21a549, b51b8c0e-494d-488b-98d5-a70fd9451b90, 75076d6a-8d3f-49e3-b4f4-7c889bc82806, 7e0b2b37-73b8-4c69-bb11-6ba954fa0cd9, 08ea0...   \n",
       "..                                                                                                                                                                                                       ...   \n",
       "639                                                                                                                                                                   [68328f42-9276-423e-80d0-fe89630804ff]   \n",
       "640                                                                                                                                                                   [63143067-46e0-4fb5-b131-d83ee45122ab]   \n",
       "641                                                                                                                                                                   [6ddcfbc9-fa06-4b14-b9a4-ce96d3fae65e]   \n",
       "642                                                                                                                                                                   [903326f2-b372-4786-9973-87226cb15e41]   \n",
       "643                                                                                                                                                                   [8b0feea6-20e4-45dc-aaae-c8b6fbd5a9f4]   \n",
       "\n",
       "                                                                                                                                                                                       Unique HDX dataset id  \\\n",
       "0    [who-data-for-south-sudan, who-data-for-montenegro, who-data-for-zimbabwe, who-data-for-zambia, who-data-for-yemen, who-data-for-viet-nam, who-data-for-venezuela-bolivarian-republic-of, who-data-f...   \n",
       "1    [world-bank-combined-indicators-for-zimbabwe, world-bank-trade-indicators-for-zimbabwe, world-bank-external-debt-indicators-for-zimbabwe, world-bank-climate-change-indicators-for-zimbabwe, world-b...   \n",
       "2    [dhs-data-for-sao-tome-and-principe, dhs-data-for-rwanda, dhs-data-for-philippines, dhs-data-for-peru, dhs-data-for-paraguay, dhs-data-for-papua-new-guinea, dhs-data-for-pakistan, dhs-data-for-nig...   \n",
       "3    [dhs-subnational-data-for-sao-tome-and-principe, dhs-subnational-data-for-rwanda, dhs-subnational-data-for-philippines, dhs-subnational-data-for-peru, dhs-subnational-data-for-paraguay, dhs-subnat...   \n",
       "4    [unhcr-population-data-for-world, unhcr-population-data-for-zwe, unhcr-population-data-for-zmb, unhcr-population-data-for-zaf, unhcr-population-data-for-yem, unhcr-population-data-for-wsm, unhcr-p...   \n",
       "..                                                                                                                                                                                                       ...   \n",
       "639                                                                                                                                                                                       [3w-december-2017]   \n",
       "640                                                                                                                                                                                   [ethiopia-settlements]   \n",
       "641                                                                                                                                               [base-acceso-internet-personas-entre-los-5-y-19-anos-2018]   \n",
       "642                                                                                                                                                                               [people-in-need-2008-2019]   \n",
       "643                                                                                                                                                                            [burkina-faso-plan-d-urgence]   \n",
       "\n",
       "            Unique Data provider  \n",
       "0    [world-health-organization]  \n",
       "1             [world-bank-group]  \n",
       "2                          [dhs]  \n",
       "3                          [dhs]  \n",
       "4                        [unhcr]  \n",
       "..                           ...  \n",
       "639              [ocha-ethiopia]  \n",
       "640              [ocha-ethiopia]  \n",
       "641                      [immap]  \n",
       "642                   [ocha-fts]  \n",
       "643                 [ocha-rowca]  \n",
       "\n",
       "[644 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hash_resources = df.groupby('Hash')['HDX resource id'].nunique().sort_values(ascending=False)\n",
    "\n",
    "for col in ['HDX resource id', 'HDX dataset id', 'Data provider']:\n",
    "    hash_resources  = hash_resources .reset_index()\n",
    "    hash_resources [f\"Unique {col}\"] = hash_resources ['Hash'].map(df.groupby('Hash')[col].unique())\n",
    "\n",
    "display(hash_resources )\n",
    "\n",
    "hash_resources.to_excel(\"./data/hxl_hash_resources.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      51b2e4ec-aca5-4b97-bbb7-c005175b682e\n",
      "1      2e130cdf-c850-4533-b2f3-e961adbec48a\n",
      "2      9c751883-698a-4a2c-9475-ff828e9c11db\n",
      "3      ed7b5bd2-7818-4d7a-9ff0-8ba0d97bf7d5\n",
      "4      295cd9e4-8464-43ee-ad17-47196991a1f7\n",
      "                       ...                 \n",
      "639    68328f42-9276-423e-80d0-fe89630804ff\n",
      "640    63143067-46e0-4fb5-b131-d83ee45122ab\n",
      "641    6ddcfbc9-fa06-4b14-b9a4-ce96d3fae65e\n",
      "642    903326f2-b372-4786-9973-87226cb15e41\n",
      "643    8b0feea6-20e4-45dc-aaae-c8b6fbd5a9f4\n",
      "Name: Unique HDX resource id, Length: 644, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extract a single resource_id for each hash\n",
    "resource_ids = hash_resources['Unique HDX resource id'].apply(lambda x: x[0])\n",
    "print(resource_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column data subset to one resource ID per hash ...\n",
      "(7834, 9)\n",
      "Unique data providers ...\n",
      "119\n",
      "Unique HDX resource ids ...\n",
      "644\n"
     ]
    }
   ],
   "source": [
    "df_subset = df[df['HDX resource id'].isin(resource_ids)]\n",
    "\n",
    "print(\"Column data subset to one resource ID per hash ...\")\n",
    "print(df_subset.shape)\n",
    "\n",
    "print(\"Unique data providers ...\")\n",
    "print(len(df_subset[\"Data provider\"].unique()))\n",
    "\n",
    "print(\"Unique HDX resource ids ...\")\n",
    "print(len(df_subset[\"HDX resource id\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data excerpts\n",
    "\n",
    "Using our subset of resource_ids for each hash, extract column data excerpts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_subset.copy()\n",
    "\n",
    "df2['Data excerpt'] = ''\n",
    "\n",
    "datasets_resources = df2[['HDX dataset id', 'HDX resource id']].drop_duplicates()\n",
    "datasets_resources.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"For each resource, extract a data excerpt for each column ...\")\n",
    "\n",
    "num_rows = datasets_resources.shape[0]\n",
    "for index, row in datasets_resources.iterrows():\n",
    "\n",
    "    if index % 10 == 0:\n",
    "        print(f\"Processing {index} of {num_rows} ({(index/num_rows)*100:.2f}%)\")\n",
    "\n",
    "    dataset_id = row['HDX dataset id']\n",
    "    resource_id = row['HDX resource id']\n",
    "    dataset = Dataset.read_from_hdx(dataset_id)\n",
    "    if dataset is None:\n",
    "        print(f\"Dataset {dataset_id} not found!\")\n",
    "        continue\n",
    "    resources = dataset.get_resources()\n",
    "    for resource in resources:\n",
    "        if resource['id'] == resource_id:\n",
    "            print(f\"    Accessing data for resource {resource_id}, {resource['name']}\")\n",
    "            try:\n",
    "                url, path = resource.download(LOCAL_DATA_DIR)\n",
    "                df2.loc[df2['HDX resource id'] == resource_id, 'File'] = path\n",
    "                df2.loc[df2['HDX resource id'] == resource_id, 'URL'] = url\n",
    "\n",
    "                with hxl.data(resource['url'], input_options) as source:\n",
    "                    columns = [column.header for column in source.columns]\n",
    "                    tags = [column.get_display_tag(sort_attributes=True) for column in source.columns]\n",
    "                    data = {}\n",
    "                    rowcount = 0\n",
    "                    for row in source:\n",
    "                        if rowcount > DATA_EXCERPT_SIZE:\n",
    "                            break\n",
    "                        i = 0\n",
    "                        for colvalue in row:\n",
    "                            colname = columns[i]\n",
    "                            if colname not in data:\n",
    "                                data[colname] = [colvalue]\n",
    "                            else:\n",
    "                                data[colname].append(colvalue)     \n",
    "                            i += 1\n",
    "                        rowcount += 1                            \n",
    "\n",
    "                    for col in columns:\n",
    "                        if col in data:\n",
    "                            print(f\"       Setting data excerpt for column {col} >> {data[col]} ...\")\n",
    "                            df2.loc[(df2['HDX resource id'] == resource_id) & (df2['Text header'] == col), 'Data excerpt'] = str(data[col])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error accessing data for resource {resource_id}, {resource['name']} ... {e}\")\n",
    "\n",
    "display(df2)\n",
    "print(df2.shape)\n",
    "df2.to_csv(\"./data/hxl_hash_resources_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data\n",
    "\n",
    "In this section we will create train and test datasets for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7834, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtag with Attributes</th>\n",
       "      <th>Text header</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Data provider</th>\n",
       "      <th>HDX dataset id</th>\n",
       "      <th>HDX resource id</th>\n",
       "      <th>Date created</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Hash</th>\n",
       "      <th>Data excerpt</th>\n",
       "      <th>File</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#affected+hh</td>\n",
       "      <td>Total IDP HH</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "      <td>[319283]</td>\n",
       "      <td>./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx</td>\n",
       "      <td>https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#affected+idp+ind</td>\n",
       "      <td>Total IDP IND</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "      <td>[1548732]</td>\n",
       "      <td>./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx</td>\n",
       "      <td>https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#affected+idp+male</td>\n",
       "      <td>Total IDP Male Ind</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "      <td>[646805]</td>\n",
       "      <td>./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx</td>\n",
       "      <td>https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#affected+female+idp</td>\n",
       "      <td>Total IDP Female Ind</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "      <td>[901927]</td>\n",
       "      <td>./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx</td>\n",
       "      <td>https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#affected+ind+returnees</td>\n",
       "      <td>Total Returnees</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "      <td>[587705]</td>\n",
       "      <td>./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx</td>\n",
       "      <td>https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td>#lat_deg</td>\n",
       "      <td>prevlat</td>\n",
       "      <td>VUT</td>\n",
       "      <td>brcmapsteam</td>\n",
       "      <td>cyclone-pam-path</td>\n",
       "      <td>a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d4a8deeb40f76ce</td>\n",
       "      <td>['-8.5', '-8.5', '-8.4', '-9.8', '-10.6', '-11.1', '-11', '-11.2', '-11.5', '-11.9', '-12.6']</td>\n",
       "      <td>./data/hdx-hxl/Cyclone Pam Path.google sheet</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>#lon_deg</td>\n",
       "      <td>prevlon</td>\n",
       "      <td>VUT</td>\n",
       "      <td>brcmapsteam</td>\n",
       "      <td>cyclone-pam-path</td>\n",
       "      <td>a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d4a8deeb40f76ce</td>\n",
       "      <td>['169.8', '169.8', '170.3', '170.5', '170.3', '170.1', '169.6', '169.7', '169.7', '170.1', '170.2']</td>\n",
       "      <td>./data/hdx-hxl/Cyclone Pam Path.google sheet</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7831</th>\n",
       "      <td>#period_date</td>\n",
       "      <td>datelabel</td>\n",
       "      <td>VUT</td>\n",
       "      <td>brcmapsteam</td>\n",
       "      <td>cyclone-pam-path</td>\n",
       "      <td>a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d4a8deeb40f76ce</td>\n",
       "      <td>['09 Mar', '09 Mar', '10 Mar', '10 Mar', '10 Mar', '11 Mar', '11 Mar', '11 Mar', '11 Mar', '12 Mar', '12 Mar']</td>\n",
       "      <td>./data/hdx-hxl/Cyclone Pam Path.google sheet</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7832</th>\n",
       "      <td>#x_time</td>\n",
       "      <td>hours</td>\n",
       "      <td>VUT</td>\n",
       "      <td>brcmapsteam</td>\n",
       "      <td>cyclone-pam-path</td>\n",
       "      <td>a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d4a8deeb40f76ce</td>\n",
       "      <td>['0', '6', '18', '30', '36', '42', '48', '54', '60', '66', '72']</td>\n",
       "      <td>./data/hdx-hxl/Cyclone Pam Path.google sheet</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>#x_note</td>\n",
       "      <td>text</td>\n",
       "      <td>VUT</td>\n",
       "      <td>brcmapsteam</td>\n",
       "      <td>cyclone-pam-path</td>\n",
       "      <td>a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d4a8deeb40f76ce</td>\n",
       "      <td>['text1', 'text2', 'text3', 'text4', 'text5', 'text6', 'text7', 'text8', 'text9', 'text10', 'text11']</td>\n",
       "      <td>./data/hdx-hxl/Cyclone Pam Path.google sheet</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7834 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hashtag with Attributes           Text header Locations  \\\n",
       "0                #affected+hh          Total IDP HH       COD   \n",
       "1           #affected+idp+ind         Total IDP IND       COD   \n",
       "2          #affected+idp+male    Total IDP Male Ind       COD   \n",
       "3        #affected+female+idp  Total IDP Female Ind       COD   \n",
       "4     #affected+ind+returnees       Total Returnees       COD   \n",
       "...                       ...                   ...       ...   \n",
       "7829                 #lat_deg               prevlat       VUT   \n",
       "7830                 #lon_deg               prevlon       VUT   \n",
       "7831             #period_date             datelabel       VUT   \n",
       "7832                  #x_time                 hours       VUT   \n",
       "7833                  #x_note                  text       VUT   \n",
       "\n",
       "                                 Data provider  \\\n",
       "0     international-organization-for-migration   \n",
       "1     international-organization-for-migration   \n",
       "2     international-organization-for-migration   \n",
       "3     international-organization-for-migration   \n",
       "4     international-organization-for-migration   \n",
       "...                                        ...   \n",
       "7829                               brcmapsteam   \n",
       "7830                               brcmapsteam   \n",
       "7831                               brcmapsteam   \n",
       "7832                               brcmapsteam   \n",
       "7833                               brcmapsteam   \n",
       "\n",
       "                                                                                  HDX dataset id  \\\n",
       "0     drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "1     drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "2     drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "3     drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "4     drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "...                                                                                          ...   \n",
       "7829                                                                            cyclone-pam-path   \n",
       "7830                                                                            cyclone-pam-path   \n",
       "7831                                                                            cyclone-pam-path   \n",
       "7832                                                                            cyclone-pam-path   \n",
       "7833                                                                            cyclone-pam-path   \n",
       "\n",
       "                           HDX resource id Date created Unnamed: 9  \\\n",
       "0     26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       True   \n",
       "1     26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       True   \n",
       "2     26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       True   \n",
       "3     26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       True   \n",
       "4     26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       True   \n",
       "...                                    ...          ...        ...   \n",
       "7829  a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3   2015-03-16       True   \n",
       "7830  a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3   2015-03-16       True   \n",
       "7831  a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3   2015-03-16       True   \n",
       "7832  a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3   2015-03-16       True   \n",
       "7833  a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3   2015-03-16       True   \n",
       "\n",
       "                    Hash  \\\n",
       "0     0x2cc7fd3129c0d18c   \n",
       "1     0x2cc7fd3129c0d18c   \n",
       "2     0x2cc7fd3129c0d18c   \n",
       "3     0x2cc7fd3129c0d18c   \n",
       "4     0x2cc7fd3129c0d18c   \n",
       "...                  ...   \n",
       "7829  0x1d4a8deeb40f76ce   \n",
       "7830  0x1d4a8deeb40f76ce   \n",
       "7831  0x1d4a8deeb40f76ce   \n",
       "7832  0x1d4a8deeb40f76ce   \n",
       "7833  0x1d4a8deeb40f76ce   \n",
       "\n",
       "                                                                                                        Data excerpt  \\\n",
       "0                                                                                                           [319283]   \n",
       "1                                                                                                          [1548732]   \n",
       "2                                                                                                           [646805]   \n",
       "3                                                                                                           [901927]   \n",
       "4                                                                                                           [587705]   \n",
       "...                                                                                                              ...   \n",
       "7829                   ['-8.5', '-8.5', '-8.4', '-9.8', '-10.6', '-11.1', '-11', '-11.2', '-11.5', '-11.9', '-12.6']   \n",
       "7830             ['169.8', '169.8', '170.3', '170.5', '170.3', '170.1', '169.6', '169.7', '169.7', '170.1', '170.2']   \n",
       "7831  ['09 Mar', '09 Mar', '10 Mar', '10 Mar', '10 Mar', '11 Mar', '11 Mar', '11 Mar', '11 Mar', '12 Mar', '12 Mar']   \n",
       "7832                                                ['0', '6', '18', '30', '36', '42', '48', '54', '60', '66', '72']   \n",
       "7833           ['text1', 'text2', 'text3', 'text4', 'text5', 'text6', 'text7', 'text8', 'text9', 'text10', 'text11']   \n",
       "\n",
       "                                                                               File  \\\n",
       "0     ./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx   \n",
       "1     ./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx   \n",
       "2     ./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx   \n",
       "3     ./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx   \n",
       "4     ./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx   \n",
       "...                                                                             ...   \n",
       "7829                                   ./data/hdx-hxl/Cyclone Pam Path.google sheet   \n",
       "7830                                   ./data/hdx-hxl/Cyclone Pam Path.google sheet   \n",
       "7831                                   ./data/hdx-hxl/Cyclone Pam Path.google sheet   \n",
       "7832                                   ./data/hdx-hxl/Cyclone Pam Path.google sheet   \n",
       "7833                                   ./data/hdx-hxl/Cyclone Pam Path.google sheet   \n",
       "\n",
       "                                                                                                                                                                      URL  \n",
       "0     https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx  \n",
       "1     https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx  \n",
       "2     https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx  \n",
       "3     https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx  \n",
       "4     https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx  \n",
       "...                                                                                                                                                                   ...  \n",
       "7829                                                                 https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing  \n",
       "7830                                                                 https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing  \n",
       "7831                                                                 https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing  \n",
       "7832                                                                 https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing  \n",
       "7833                                                                 https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing  \n",
       "\n",
       "[7834 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/hxl_hash_resources_data.csv\")\n",
    "print(data.shape)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6737, 12)\n"
     ]
    }
   ],
   "source": [
    "data = data[data['Data excerpt'].notnull()]\n",
    "data = data[data['Data excerpt'].str.contains(r'[A-Za-z0-9]')]\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1En9FlmM8PrbTWgl3UHPF_MXnJ6ziVZFhBbojSJzBdLI\n",
      "From (redirected): https://docs.google.com/spreadsheets/d/1En9FlmM8PrbTWgl3UHPF_MXnJ6ziVZFhBbojSJzBdLI/export?format=xlsx\n",
      "To: /Users/matthewharris/Desktop/git/hxl_metadata_prediction/data/hdx-hxl/hxl-core-schema.xlsx\n",
      "240kB [00:00, 18.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "HXL_CORE_SCHEMA=\"https://docs.google.com/spreadsheets/d/1En9FlmM8PrbTWgl3UHPF_MXnJ6ziVZFhBbojSJzBdLI/edit?usp=sharing\"\n",
    "\n",
    "local_data_file = LOCAL_DATA_DIR + \"/hxl-core-schema.xlsx\"\n",
    "\n",
    "gdown.download(HXL_CORE_SCHEMA, local_data_file, quiet=False, fuzzy=True)\n",
    "\n",
    "df= pd.read_excel(local_data_file, sheet_name='Core hashtags')\n",
    "hashtags_list = df['Hashtag'][1:].tolist()\n",
    "\n",
    "df= pd.read_excel(local_data_file, sheet_name='Core attributes')\n",
    "attributes_list = df['Attribute'][1:].tolist()\n",
    "\n",
    "# Remove rows with disallowed tags or attributes\n",
    "APPROVED_HXL_SCHEMA = hashtags_list + attributes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove disallowed HXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before (6737, 12)\n",
      "After (3368, 12)\n",
      "(3368, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtag with Attributes</th>\n",
       "      <th>Text header</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Data provider</th>\n",
       "      <th>HDX dataset id</th>\n",
       "      <th>HDX resource id</th>\n",
       "      <th>Date created</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Hash</th>\n",
       "      <th>Data excerpt</th>\n",
       "      <th>File</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#affected+idp+ind</td>\n",
       "      <td>Total IDP IND</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "      <td>[1548732]</td>\n",
       "      <td>./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx</td>\n",
       "      <td>https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#affected+idp+male</td>\n",
       "      <td>Total IDP Male Ind</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "      <td>[646805]</td>\n",
       "      <td>./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx</td>\n",
       "      <td>https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#affected+female+idp</td>\n",
       "      <td>Total IDP Female Ind</td>\n",
       "      <td>COD</td>\n",
       "      <td>international-organization-for-migration</td>\n",
       "      <td>drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm</td>\n",
       "      <td>26ecc26f-74e7-46af-b450-8872dca0b63b</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x2cc7fd3129c0d18c</td>\n",
       "      <td>[901927]</td>\n",
       "      <td>./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx</td>\n",
       "      <td>https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>#meta+appeal+type</td>\n",
       "      <td>atype</td>\n",
       "      <td>SSD</td>\n",
       "      <td>ifrc</td>\n",
       "      <td>ifrc-appeals-data-for-south-sudan</td>\n",
       "      <td>4110b824-3338-453f-ae5d-89ca80f5b147</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d1434ee319a1be</td>\n",
       "      <td>['0', '0', '0', '1', '0', '0', '2', '0', '0', '1', '0']</td>\n",
       "      <td>./data/hdx-hxl/IFRC Appeals Data for South Sudan.csv</td>\n",
       "      <td>https://data.humdata.org/dataset/db2f8c45-7992-4f23-99f5-e8b4d853b53d/resource/4110b824-3338-453f-ae5d-89ca80f5b147/download/appeals_data_ssd.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>#meta+appeal+id</td>\n",
       "      <td>code</td>\n",
       "      <td>SSD</td>\n",
       "      <td>ifrc</td>\n",
       "      <td>ifrc-appeals-data-for-south-sudan</td>\n",
       "      <td>4110b824-3338-453f-ae5d-89ca80f5b147</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d1434ee319a1be</td>\n",
       "      <td>['MDRSS013', 'MDRSS012', 'MDRSS011', 'MDRSS009', 'MDRSS008', 'MDRSS007', 'MDRSS006', 'MDRSS005', 'MDRSS004', 'MDRSS003', 'MDRSS002']</td>\n",
       "      <td>./data/hdx-hxl/IFRC Appeals Data for South Sudan.csv</td>\n",
       "      <td>https://data.humdata.org/dataset/db2f8c45-7992-4f23-99f5-e8b4d853b53d/resource/4110b824-3338-453f-ae5d-89ca80f5b147/download/appeals_data_ssd.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td>#lat_deg</td>\n",
       "      <td>prevlat</td>\n",
       "      <td>VUT</td>\n",
       "      <td>brcmapsteam</td>\n",
       "      <td>cyclone-pam-path</td>\n",
       "      <td>a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d4a8deeb40f76ce</td>\n",
       "      <td>['-8.5', '-8.5', '-8.4', '-9.8', '-10.6', '-11.1', '-11', '-11.2', '-11.5', '-11.9', '-12.6']</td>\n",
       "      <td>./data/hdx-hxl/Cyclone Pam Path.google sheet</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>#lon_deg</td>\n",
       "      <td>prevlon</td>\n",
       "      <td>VUT</td>\n",
       "      <td>brcmapsteam</td>\n",
       "      <td>cyclone-pam-path</td>\n",
       "      <td>a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d4a8deeb40f76ce</td>\n",
       "      <td>['169.8', '169.8', '170.3', '170.5', '170.3', '170.1', '169.6', '169.7', '169.7', '170.1', '170.2']</td>\n",
       "      <td>./data/hdx-hxl/Cyclone Pam Path.google sheet</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7831</th>\n",
       "      <td>#period_date</td>\n",
       "      <td>datelabel</td>\n",
       "      <td>VUT</td>\n",
       "      <td>brcmapsteam</td>\n",
       "      <td>cyclone-pam-path</td>\n",
       "      <td>a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d4a8deeb40f76ce</td>\n",
       "      <td>['09 Mar', '09 Mar', '10 Mar', '10 Mar', '10 Mar', '11 Mar', '11 Mar', '11 Mar', '11 Mar', '12 Mar', '12 Mar']</td>\n",
       "      <td>./data/hdx-hxl/Cyclone Pam Path.google sheet</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7832</th>\n",
       "      <td>#x_time</td>\n",
       "      <td>hours</td>\n",
       "      <td>VUT</td>\n",
       "      <td>brcmapsteam</td>\n",
       "      <td>cyclone-pam-path</td>\n",
       "      <td>a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d4a8deeb40f76ce</td>\n",
       "      <td>['0', '6', '18', '30', '36', '42', '48', '54', '60', '66', '72']</td>\n",
       "      <td>./data/hdx-hxl/Cyclone Pam Path.google sheet</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>#x_note</td>\n",
       "      <td>text</td>\n",
       "      <td>VUT</td>\n",
       "      <td>brcmapsteam</td>\n",
       "      <td>cyclone-pam-path</td>\n",
       "      <td>a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>True</td>\n",
       "      <td>0x1d4a8deeb40f76ce</td>\n",
       "      <td>['text1', 'text2', 'text3', 'text4', 'text5', 'text6', 'text7', 'text8', 'text9', 'text10', 'text11']</td>\n",
       "      <td>./data/hdx-hxl/Cyclone Pam Path.google sheet</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3369 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hashtag with Attributes           Text header Locations  \\\n",
       "1          #affected+idp+ind         Total IDP IND       COD   \n",
       "2         #affected+idp+male    Total IDP Male Ind       COD   \n",
       "3       #affected+female+idp  Total IDP Female Ind       COD   \n",
       "15         #meta+appeal+type                 atype       SSD   \n",
       "18           #meta+appeal+id                  code       SSD   \n",
       "...                      ...                   ...       ...   \n",
       "7829                #lat_deg               prevlat       VUT   \n",
       "7830                #lon_deg               prevlon       VUT   \n",
       "7831            #period_date             datelabel       VUT   \n",
       "7832                 #x_time                 hours       VUT   \n",
       "7833                 #x_note                  text       VUT   \n",
       "\n",
       "                                 Data provider  \\\n",
       "1     international-organization-for-migration   \n",
       "2     international-organization-for-migration   \n",
       "3     international-organization-for-migration   \n",
       "15                                        ifrc   \n",
       "18                                        ifrc   \n",
       "...                                        ...   \n",
       "7829                               brcmapsteam   \n",
       "7830                               brcmapsteam   \n",
       "7831                               brcmapsteam   \n",
       "7832                               brcmapsteam   \n",
       "7833                               brcmapsteam   \n",
       "\n",
       "                                                                                  HDX dataset id  \\\n",
       "1     drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "2     drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "3     drc-displacement-idps-returnees-m23-crisis-north-kivu-province-baseline-assessment-iom-dtm   \n",
       "15                                                             ifrc-appeals-data-for-south-sudan   \n",
       "18                                                             ifrc-appeals-data-for-south-sudan   \n",
       "...                                                                                          ...   \n",
       "7829                                                                            cyclone-pam-path   \n",
       "7830                                                                            cyclone-pam-path   \n",
       "7831                                                                            cyclone-pam-path   \n",
       "7832                                                                            cyclone-pam-path   \n",
       "7833                                                                            cyclone-pam-path   \n",
       "\n",
       "                           HDX resource id Date created Unnamed: 9  \\\n",
       "1     26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       True   \n",
       "2     26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       True   \n",
       "3     26ecc26f-74e7-46af-b450-8872dca0b63b   2023-10-16       True   \n",
       "15    4110b824-3338-453f-ae5d-89ca80f5b147   2023-03-13       True   \n",
       "18    4110b824-3338-453f-ae5d-89ca80f5b147   2023-03-13       True   \n",
       "...                                    ...          ...        ...   \n",
       "7829  a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3   2015-03-16       True   \n",
       "7830  a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3   2015-03-16       True   \n",
       "7831  a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3   2015-03-16       True   \n",
       "7832  a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3   2015-03-16       True   \n",
       "7833  a8ccd9d2-8328-487a-b04b-ca3f3f2e0ea3   2015-03-16       True   \n",
       "\n",
       "                    Hash  \\\n",
       "1     0x2cc7fd3129c0d18c   \n",
       "2     0x2cc7fd3129c0d18c   \n",
       "3     0x2cc7fd3129c0d18c   \n",
       "15     0x1d1434ee319a1be   \n",
       "18     0x1d1434ee319a1be   \n",
       "...                  ...   \n",
       "7829  0x1d4a8deeb40f76ce   \n",
       "7830  0x1d4a8deeb40f76ce   \n",
       "7831  0x1d4a8deeb40f76ce   \n",
       "7832  0x1d4a8deeb40f76ce   \n",
       "7833  0x1d4a8deeb40f76ce   \n",
       "\n",
       "                                                                                                                              Data excerpt  \\\n",
       "1                                                                                                                                [1548732]   \n",
       "2                                                                                                                                 [646805]   \n",
       "3                                                                                                                                 [901927]   \n",
       "15                                                                                 ['0', '0', '0', '1', '0', '0', '2', '0', '0', '1', '0']   \n",
       "18    ['MDRSS013', 'MDRSS012', 'MDRSS011', 'MDRSS009', 'MDRSS008', 'MDRSS007', 'MDRSS006', 'MDRSS005', 'MDRSS004', 'MDRSS003', 'MDRSS002']   \n",
       "...                                                                                                                                    ...   \n",
       "7829                                         ['-8.5', '-8.5', '-8.4', '-9.8', '-10.6', '-11.1', '-11', '-11.2', '-11.5', '-11.9', '-12.6']   \n",
       "7830                                   ['169.8', '169.8', '170.3', '170.5', '170.3', '170.1', '169.6', '169.7', '169.7', '170.1', '170.2']   \n",
       "7831                        ['09 Mar', '09 Mar', '10 Mar', '10 Mar', '10 Mar', '11 Mar', '11 Mar', '11 Mar', '11 Mar', '12 Mar', '12 Mar']   \n",
       "7832                                                                      ['0', '6', '18', '30', '36', '42', '48', '54', '60', '66', '72']   \n",
       "7833                                 ['text1', 'text2', 'text3', 'text4', 'text5', 'text6', 'text7', 'text8', 'text9', 'text10', 'text11']   \n",
       "\n",
       "                                                                               File  \\\n",
       "1     ./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx   \n",
       "2     ./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx   \n",
       "3     ./data/hdx-hxl/DRC - Baseline Assessment - M23 Crisis 13 - February 2024.xlsx   \n",
       "15                             ./data/hdx-hxl/IFRC Appeals Data for South Sudan.csv   \n",
       "18                             ./data/hdx-hxl/IFRC Appeals Data for South Sudan.csv   \n",
       "...                                                                             ...   \n",
       "7829                                   ./data/hdx-hxl/Cyclone Pam Path.google sheet   \n",
       "7830                                   ./data/hdx-hxl/Cyclone Pam Path.google sheet   \n",
       "7831                                   ./data/hdx-hxl/Cyclone Pam Path.google sheet   \n",
       "7832                                   ./data/hdx-hxl/Cyclone Pam Path.google sheet   \n",
       "7833                                   ./data/hdx-hxl/Cyclone Pam Path.google sheet   \n",
       "\n",
       "                                                                                                                                                                      URL  \n",
       "1     https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx  \n",
       "2     https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx  \n",
       "3     https://data.humdata.org/dataset/3554c498-660a-45cb-ada5-86a1fbcd6056/resource/26ecc26f-74e7-46af-b450-8872dca0b63b/download/adc_27jan-12_feb_update_public_v2.xlsx  \n",
       "15                      https://data.humdata.org/dataset/db2f8c45-7992-4f23-99f5-e8b4d853b53d/resource/4110b824-3338-453f-ae5d-89ca80f5b147/download/appeals_data_ssd.csv  \n",
       "18                      https://data.humdata.org/dataset/db2f8c45-7992-4f23-99f5-e8b4d853b53d/resource/4110b824-3338-453f-ae5d-89ca80f5b147/download/appeals_data_ssd.csv  \n",
       "...                                                                                                                                                                   ...  \n",
       "7829                                                                 https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing  \n",
       "7830                                                                 https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing  \n",
       "7831                                                                 https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing  \n",
       "7832                                                                 https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing  \n",
       "7833                                                                 https://docs.google.com/spreadsheets/d/1xFOPVLCKeVpLtM27loV3_zicG-xswOZk7SD_nAQ217Q/edit?usp=sharing  \n",
       "\n",
       "[3369 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_for_schema(text):\n",
    "    #print(f\"Tokens before: {text}\")\n",
    "    if \" \" in text:\n",
    "        text = text.replace(\" \",\"\")\n",
    "\n",
    "    tokens_raw = text.split(\"+\")\n",
    "    tokens = [tokens_raw[0]]\n",
    "    for t in tokens_raw[1:]:\n",
    "        tokens.append(f\"+{t}\")\n",
    "\n",
    "    filtered = []\n",
    "    for t in tokens:\n",
    "        if t in APPROVED_HXL_SCHEMA:\n",
    "            if t not in filtered:\n",
    "                filtered.append(t)\n",
    "    filtered = \"\".join(filtered)\n",
    "\n",
    "    if len(filtered) > 0 and filtered[0] != '#':\n",
    "        filtered = \"\"\n",
    "\n",
    "    # Add spaces back in\n",
    "    # filtered = filtered.replace(\"+\", \" +\")\n",
    "\n",
    "    #print(f\"        After: {filtered}\")\n",
    "    return filtered\n",
    "\n",
    "def filter_disallowed_hxl(column_data, hxl_col = 'Hashtag with Attributes'):\n",
    "    print(\"Before\",column_data.shape)\n",
    "    allowed = []\n",
    "    disallowed = []\n",
    "    for index, row in column_data.iterrows():\n",
    "        if row[hxl_col] == filter_for_schema(row[hxl_col]):\n",
    "            allowed.append(row)\n",
    "        else:\n",
    "            disallowed.append(row)\n",
    "    allowed = pd.DataFrame(allowed)\n",
    "    disallowed = pd.DataFrame(disallowed)\n",
    "    print(\"After\", allowed.shape)\n",
    "    return allowed, disallowed\n",
    "\n",
    "data, disallowed = filter_disallowed_hxl(data)\n",
    "print(data.shape)\n",
    "\n",
    "display(disallowed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag\n",
      "#adm1           527\n",
      "#adm2           477\n",
      "#affected       380\n",
      "#country        287\n",
      "#date           244\n",
      "#org            232\n",
      "#adm3           188\n",
      "#inneed         141\n",
      "#sector         111\n",
      "#geo            106\n",
      "#targeted        77\n",
      "#loc             67\n",
      "#activity        67\n",
      "#status          60\n",
      "#population      57\n",
      "#indicator       55\n",
      "#region          50\n",
      "#meta            42\n",
      "#reached         36\n",
      "#adm4            32\n",
      "#event           14\n",
      "#subsector       13\n",
      "#beneficiary     12\n",
      "#cause           12\n",
      "#value           11\n",
      "#item            10\n",
      "#severity         9\n",
      "#output           8\n",
      "#crisis           6\n",
      "#currency         4\n",
      "#service          4\n",
      "#adm5             4\n",
      "#contact          4\n",
      "#access           4\n",
      "#capacity         3\n",
      "#impact           3\n",
      "#description      3\n",
      "#frequency        2\n",
      "#group            2\n",
      "#modality         2\n",
      "#delivery         1\n",
      "#operations       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['tag'] = data['Hashtag with Attributes'].apply(lambda x: x.split('+')[0])\n",
    "tag_counts_train = data['tag'].value_counts()\n",
    "\n",
    "print(tag_counts_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate training prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Split by data provider organization\n",
    "\n",
    "On HDX, the hierarchy is ...\n",
    "\n",
    "Organization > datasets > resources > tables\n",
    "\n",
    "A random train/test split will result in data from files in a dataset being in both train and test, which would pollute the test set with very similar data to training. So we will split by organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orgs which don't seem to be subsidiaries ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data provider</th>\n",
       "      <th>count</th>\n",
       "      <th>org_parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>immap</td>\n",
       "      <td>221</td>\n",
       "      <td>immap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hdx</td>\n",
       "      <td>139</td>\n",
       "      <td>hdx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hera-humanitarian-emergency-response-africa</td>\n",
       "      <td>100</td>\n",
       "      <td>hera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>redhum</td>\n",
       "      <td>69</td>\n",
       "      <td>redhum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fieldsdata</td>\n",
       "      <td>53</td>\n",
       "      <td>fieldsdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ifrc</td>\n",
       "      <td>49</td>\n",
       "      <td>ifrc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>wfp</td>\n",
       "      <td>41</td>\n",
       "      <td>wfp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>brcmapsteam</td>\n",
       "      <td>31</td>\n",
       "      <td>brcmapsteam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dhs</td>\n",
       "      <td>28</td>\n",
       "      <td>dhs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>standby-task-force</td>\n",
       "      <td>28</td>\n",
       "      <td>standby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>clear</td>\n",
       "      <td>26</td>\n",
       "      <td>clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>cerf</td>\n",
       "      <td>21</td>\n",
       "      <td>cerf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>insecurity-insight</td>\n",
       "      <td>17</td>\n",
       "      <td>insecurity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>un-ocha</td>\n",
       "      <td>15</td>\n",
       "      <td>un</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>education-cluster-yemen</td>\n",
       "      <td>13</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>iati</td>\n",
       "      <td>12</td>\n",
       "      <td>iati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>crs-waro</td>\n",
       "      <td>11</td>\n",
       "      <td>crs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>hrrp-nepal</td>\n",
       "      <td>11</td>\n",
       "      <td>hrrp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>qcri</td>\n",
       "      <td>10</td>\n",
       "      <td>qcri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>global-shelter-cluster</td>\n",
       "      <td>10</td>\n",
       "      <td>global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>cbes</td>\n",
       "      <td>10</td>\n",
       "      <td>cbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>meers</td>\n",
       "      <td>9</td>\n",
       "      <td>meers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>water-point-data-exchange</td>\n",
       "      <td>9</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>undp-human-development-reports-office</td>\n",
       "      <td>8</td>\n",
       "      <td>undp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>awsd</td>\n",
       "      <td>8</td>\n",
       "      <td>awsd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>cpaor</td>\n",
       "      <td>8</td>\n",
       "      <td>cpaor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>inter-sector-coordination-group</td>\n",
       "      <td>8</td>\n",
       "      <td>inter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>cred</td>\n",
       "      <td>7</td>\n",
       "      <td>cred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>lacso</td>\n",
       "      <td>7</td>\n",
       "      <td>lacso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>interaction</td>\n",
       "      <td>7</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>netherlands-red-cross</td>\n",
       "      <td>6</td>\n",
       "      <td>netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>cesvi</td>\n",
       "      <td>6</td>\n",
       "      <td>cesvi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ourairports</td>\n",
       "      <td>6</td>\n",
       "      <td>ourairports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>gec</td>\n",
       "      <td>6</td>\n",
       "      <td>gec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>eth-zurich-weather-and-climate-risks</td>\n",
       "      <td>5</td>\n",
       "      <td>eth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>cirrolytix</td>\n",
       "      <td>5</td>\n",
       "      <td>cirrolytix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>unrwa-for-palestine-refugees-in-the-near-east</td>\n",
       "      <td>5</td>\n",
       "      <td>unrwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>rca</td>\n",
       "      <td>5</td>\n",
       "      <td>rca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>health-cluster</td>\n",
       "      <td>5</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>hxl</td>\n",
       "      <td>5</td>\n",
       "      <td>hxl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>idi</td>\n",
       "      <td>5</td>\n",
       "      <td>idi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>libya-ingo-forum</td>\n",
       "      <td>5</td>\n",
       "      <td>libya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>jhucsse</td>\n",
       "      <td>5</td>\n",
       "      <td>jhucsse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ewipa</td>\n",
       "      <td>4</td>\n",
       "      <td>ewipa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>moving-energy-initiative</td>\n",
       "      <td>4</td>\n",
       "      <td>moving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>dalberg</td>\n",
       "      <td>4</td>\n",
       "      <td>dalberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>cfp-rco-nepal</td>\n",
       "      <td>4</td>\n",
       "      <td>cfp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>unesco</td>\n",
       "      <td>3</td>\n",
       "      <td>unesco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>unodc</td>\n",
       "      <td>3</td>\n",
       "      <td>unodc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>cimp</td>\n",
       "      <td>3</td>\n",
       "      <td>cimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>srsgcc</td>\n",
       "      <td>3</td>\n",
       "      <td>srsgcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>somalia-ngo-consortium</td>\n",
       "      <td>3</td>\n",
       "      <td>somalia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>reliefweb</td>\n",
       "      <td>3</td>\n",
       "      <td>reliefweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>blavatnik-school-of-government-university-of-oxford</td>\n",
       "      <td>3</td>\n",
       "      <td>blavatnik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>kenya-national-bureau-of-statistics</td>\n",
       "      <td>2</td>\n",
       "      <td>kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>soswcaf</td>\n",
       "      <td>2</td>\n",
       "      <td>soswcaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>rcpwca</td>\n",
       "      <td>2</td>\n",
       "      <td>rcpwca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>jcc</td>\n",
       "      <td>1</td>\n",
       "      <td>jcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>infoculture</td>\n",
       "      <td>1</td>\n",
       "      <td>infoculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>sadc_rvaa</td>\n",
       "      <td>1</td>\n",
       "      <td>sadc_rvaa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Data provider  count   org_parent\n",
       "1                                                  immap    221        immap\n",
       "2                                                    hdx    139          hdx\n",
       "5            hera-humanitarian-emergency-response-africa    100         hera\n",
       "11                                                redhum     69       redhum\n",
       "13                                            fieldsdata     53   fieldsdata\n",
       "17                                                  ifrc     49         ifrc\n",
       "20                                                   wfp     41          wfp\n",
       "25                                           brcmapsteam     31  brcmapsteam\n",
       "28                                                   dhs     28          dhs\n",
       "29                                    standby-task-force     28      standby\n",
       "30                                                 clear     26        clear\n",
       "36                                                  cerf     21         cerf\n",
       "38                                    insecurity-insight     17   insecurity\n",
       "45                                               un-ocha     15           un\n",
       "47                               education-cluster-yemen     13    education\n",
       "50                                                  iati     12         iati\n",
       "51                                              crs-waro     11          crs\n",
       "52                                            hrrp-nepal     11         hrrp\n",
       "54                                                  qcri     10         qcri\n",
       "55                                global-shelter-cluster     10       global\n",
       "56                                                  cbes     10         cbes\n",
       "58                                                 meers      9        meers\n",
       "59                             water-point-data-exchange      9        water\n",
       "61                 undp-human-development-reports-office      8         undp\n",
       "63                                                  awsd      8         awsd\n",
       "64                                                 cpaor      8        cpaor\n",
       "65                       inter-sector-coordination-group      8        inter\n",
       "66                                                  cred      7         cred\n",
       "67                                                 lacso      7        lacso\n",
       "68                                           interaction      7  interaction\n",
       "70                                 netherlands-red-cross      6  netherlands\n",
       "71                                                 cesvi      6        cesvi\n",
       "72                                           ourairports      6  ourairports\n",
       "74                                                   gec      6          gec\n",
       "76                  eth-zurich-weather-and-climate-risks      5          eth\n",
       "77                                            cirrolytix      5   cirrolytix\n",
       "79         unrwa-for-palestine-refugees-in-the-near-east      5        unrwa\n",
       "81                                                   rca      5          rca\n",
       "82                                        health-cluster      5       health\n",
       "83                                                   hxl      5          hxl\n",
       "84                                                   idi      5          idi\n",
       "85                                      libya-ingo-forum      5        libya\n",
       "86                                               jhucsse      5      jhucsse\n",
       "87                                                 ewipa      4        ewipa\n",
       "89                              moving-energy-initiative      4       moving\n",
       "90                                               dalberg      4      dalberg\n",
       "91                                         cfp-rco-nepal      4          cfp\n",
       "92                                                unesco      3       unesco\n",
       "93                                                 unodc      3        unodc\n",
       "95                                                  cimp      3         cimp\n",
       "98                                                srsgcc      3       srsgcc\n",
       "99                                somalia-ngo-consortium      3      somalia\n",
       "100                                            reliefweb      3    reliefweb\n",
       "101  blavatnik-school-of-government-university-of-oxford      3    blavatnik\n",
       "102                  kenya-national-bureau-of-statistics      2        kenya\n",
       "103                                              soswcaf      2      soswcaf\n",
       "104                                               rcpwca      2       rcpwca\n",
       "106                                                  jcc      1          jcc\n",
       "107                                          infoculture      1  infoculture\n",
       "109                                            sadc_rvaa      1    sadc_rvaa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train orgs: ['ocha-nepal', 'ocha-rosc', 'cpaor', 'ocha-yemen', 'infoculture', 'libya-ingo-forum', 'education-cluster-yemen', 'ocha-cameroon', 'brcmapsteam', 'ocha-south-sudan', 'ocha-rowca', 'cred', 'international-displacement-monitoring-centre-idmc', 'unodc', 'crs-waro', 'hdx', 'ocha-mozambique-hat', 'world-bank-group', 'reliefweb', 'insecurity-insight', 'hera-humanitarian-emergency-response-africa', 'blavatnik-school-of-government-university-of-oxford', 'ocha-eritrea', 'cbes', 'ocha-sudan', 'ocha-ukraine', 'ocha-dr-congo', 'unicef-data', 'ocha-indonesia', 'sadc_rvaa', 'qcri', 'ocha-nigeria', 'undp-human-development-reports-office', 'soswcaf', 'hrrp-nepal', 'hxl', 'ocha-burkina', 'eth-zurich-weather-and-climate-risks', 'health-cluster', 'rcpwca', 'ifrc', 'ocha-somalia', 'moving-energy-initiative', 'ourairports', 'srsgcc', 'cirrolytix', 'unicef-esaro', 'ocha-ds', 'ocha-rosea', 'dalberg', 'cesvi', 'ocha-fts', 'ocha-niger', 'unhcr-afghanistan', 'unrwa-for-palestine-refugees-in-the-near-east', 'cfp-rco-nepal', 'ocha-iraq', 'ocha-colombia', 'cerf', 'ocha-burundi', 'ipc-cluster-guinea', 'netherlands-red-cross', 'ocha-roap', 'kenya-national-bureau-of-statistics', 'ocha-opt', 'ewipa', 'ocha-afghanistan', 'fao', 'ocha-myanmar', 'inter-sector-coordination-group', 'unicef-rdc', 'ocha-chad', 'water-point-data-exchange', 'unhcr', 'jhucsse', 'iati', 'international-organization-for-migration', 'somalia-ngo-consortium', 'standby-task-force', 'ocha-libya', 'world-health-organization', 'unesco', 'ocha-mali', 'ocha-pakistan', 'ocha-car', 'ipc', 'lacso', 'ocha-ethiopia', 'redhum', 'ocha-rolac', 'ocha-haiti', 'fao-reowa', 'jcc', 'ocha-philippines', 'clear', 'awsd', 'idi', 'ocha-fiss', 'interaction', 'ocha-turkey', 'gec']\n",
      "Test orgs: ['meers' 'un-ocha' 'immap' 'dhs' 'rca' 'cimp' 'global-shelter-cluster'\n",
      " 'meers' 'wfp' 'fieldsdata']\n",
      "\n",
      "Train orgs: ['awsd' 'blavatnik-school-of-government-university-of-oxford'\n",
      " 'brcmapsteam' 'cbes' 'cerf' 'cesvi' 'cfp-rco-nepal' 'cirrolytix' 'clear'\n",
      " 'cpaor' 'cred' 'crs-waro' 'dalberg' 'education-cluster-yemen'\n",
      " 'eth-zurich-weather-and-climate-risks' 'ewipa' 'fao' 'fao-reowa' 'gec'\n",
      " 'hdx' 'health-cluster' 'hera-humanitarian-emergency-response-africa'\n",
      " 'hrrp-nepal' 'hxl' 'iati' 'idi' 'ifrc' 'infoculture' 'insecurity-insight'\n",
      " 'inter-sector-coordination-group' 'interaction'\n",
      " 'international-displacement-monitoring-centre-idmc'\n",
      " 'international-organization-for-migration' 'ipc' 'ipc-cluster-guinea'\n",
      " 'jcc' 'jhucsse' 'kenya-national-bureau-of-statistics' 'lacso'\n",
      " 'libya-ingo-forum' 'moving-energy-initiative' 'netherlands-red-cross'\n",
      " 'ocha-afghanistan' 'ocha-burkina' 'ocha-burundi' 'ocha-cameroon'\n",
      " 'ocha-car' 'ocha-chad' 'ocha-colombia' 'ocha-dr-congo' 'ocha-ds'\n",
      " 'ocha-eritrea' 'ocha-ethiopia' 'ocha-fiss' 'ocha-fts' 'ocha-haiti'\n",
      " 'ocha-indonesia' 'ocha-iraq' 'ocha-libya' 'ocha-mali'\n",
      " 'ocha-mozambique-hat' 'ocha-myanmar' 'ocha-nepal' 'ocha-niger'\n",
      " 'ocha-nigeria' 'ocha-opt' 'ocha-pakistan' 'ocha-philippines' 'ocha-roap'\n",
      " 'ocha-rolac' 'ocha-rosc' 'ocha-rosea' 'ocha-rowca' 'ocha-somalia'\n",
      " 'ocha-south-sudan' 'ocha-sudan' 'ocha-turkey' 'ocha-ukraine' 'ocha-yemen'\n",
      " 'ourairports' 'qcri' 'rcpwca' 'redhum' 'reliefweb' 'sadc_rvaa'\n",
      " 'somalia-ngo-consortium' 'soswcaf' 'srsgcc' 'standby-task-force'\n",
      " 'undp-human-development-reports-office' 'unesco' 'unhcr'\n",
      " 'unhcr-afghanistan' 'unicef-data' 'unicef-esaro' 'unicef-rdc' 'unodc'\n",
      " 'unrwa-for-palestine-refugees-in-the-near-east'\n",
      " 'water-point-data-exchange' 'world-bank-group'\n",
      " 'world-health-organization']\n",
      "\n",
      "Test orgs: ['cimp' 'dhs' 'fieldsdata' 'global-shelter-cluster' 'immap' 'meers' 'rca'\n",
      " 'un-ocha' 'wfp']\n",
      "\n",
      "Train column data: (2983, 15)\n",
      "Test column data: (385, 15)\n"
     ]
    }
   ],
   "source": [
    "def split_data(column_data, provider_col, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform train-test split on datasets, print information, and return X_train and X_test.\n",
    "\n",
    "    The split is done by organizations, to try and avoid the situation where an org provides\n",
    "    similar data files. Also, we exclude orgs which are subsidiaries from the test set, eg ocha-*\n",
    "    as presumably each subsid will provide similar data. The aim is that the test set is new.\n",
    "\n",
    "    Parameters:\n",
    "    - column_data (pd.DataFrame): DataFrame containing column data.\n",
    "    - provider_col (string): Name of column holding data providers.\n",
    "    - test_size (float): The proportion of the dataset to include in the test split.\n",
    "    - random_state (int): Seed for random number generation.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame, pd.DataFrame: X_train, X_test\n",
    "    \"\"\"\n",
    "     \n",
    "    orgs_df = column_data.groupby(provider_col)[provider_col].count().sort_values(ascending=False)\n",
    "    orgs_df = column_data.groupby(provider_col)[provider_col].count().sort_values(ascending=False).reset_index(name='count')\n",
    "    all_orgs = orgs_df[provider_col].unique()\n",
    "\n",
    "    # Split orgs to get 'Parent', eg 'ocha-*' -> 'ocha'\n",
    "    orgs_df['org_parent'] = orgs_df[provider_col].str.split('-').str[0]\n",
    "\n",
    "    # Count occurrences of each 'org_parent'\n",
    "    org_parent_counts = orgs_df['org_parent'].value_counts().reset_index(name='count')\n",
    "\n",
    "    # Filter to keep only those occurring once\n",
    "    org_parents_single_occurrence = org_parent_counts[org_parent_counts['count'] == 1]\n",
    "\n",
    "    # Get the 'org_parent' values that occur only once\n",
    "    single_occurrence_org_parents = org_parents_single_occurrence['org_parent'].tolist()\n",
    "\n",
    "    # Filter the original DataFrame to keep rows where 'org_parent' occurs only once\n",
    "    org_parents_unique = orgs_df[orgs_df['org_parent'].isin(single_occurrence_org_parents)]\n",
    "\n",
    "    print(\"\\nOrgs which don't seem to be subsidiaries ...\\n\")\n",
    "    display(org_parents_unique)\n",
    "\n",
    "    single_entities = list(org_parents_unique[provider_col].unique())\n",
    "\n",
    "    # Remove 'hdx' from single_entities, not good for testing as it's the folks that made HXL! Also some monolithic orgs with very similar data\n",
    "    single_entities = [x for x in single_entities if not x in ['hdx','ourairports']]\n",
    "\n",
    "    single_entities.sort()\n",
    "\n",
    "    # Sample single-subsid orgs\n",
    "    sample_size = int(len(single_entities)*test_size) - 1\n",
    "    np.random.seed(42)\n",
    "    X_test_orgs = np.random.choice(single_entities, sample_size)\n",
    "    X_train_orgs = list(set(all_orgs)-set(X_test_orgs))\n",
    "\n",
    "    print(f\"Train orgs: {X_train_orgs}\")\n",
    "    print(f\"Test orgs: {X_test_orgs}\")\n",
    "\n",
    "    # Extract column rows for datasets in X_train_datasets\n",
    "    X_train = column_data[column_data[provider_col].isin(X_train_orgs)]\n",
    "\n",
    "    # Extract column rows for datasets in X_test_datasets\n",
    "    X_test = column_data[~column_data[provider_col].isin(X_train_orgs)]\n",
    "\n",
    "    train_orgs = X_train[provider_col].unique()\n",
    "    train_orgs.sort()\n",
    "    test_orgs = X_test[provider_col].unique()\n",
    "    test_orgs.sort()\n",
    "\n",
    "    print(f\"\\nTrain orgs: {train_orgs}\")\n",
    "    print(f\"\\nTest orgs: {test_orgs}\")\n",
    "\n",
    "    print(f\"\\nTrain column data: {X_train.shape}\")\n",
    "    print(f\"Test column data: {X_test.shape}\")\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "X_train, X_test = split_data(data, 'Data provider', test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts written to ./data/hxl_completion_prompts.jsonl\n",
      "Prompts written to ./data/hxl_chat_prompts.jsonl\n"
     ]
    }
   ],
   "source": [
    "def create_prompt_file(X_train, prompt_col, filename):\n",
    "    \"\"\"\n",
    "    Create a prompt file from a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): The DataFrame containing the prompts.\n",
    "        prompt_col (str): The name of the column containing the prompts.\n",
    "        filename (str): The name of the file to write the prompts to.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        for index, row in X_train.iterrows():\n",
    "            f.write(row[prompt_col] + \"\\n\")\n",
    "\n",
    "    print(f\"Prompts written to {filename}\")\n",
    "\n",
    "def generate_completion_prompt(dataset_name, resource_name, column_name, excerpt, hxl_tag=None, add_response=True):\n",
    "    \"\"\"\n",
    "    Generate a completion (eg Davinci) fine-tuning prompt for HXL tags given dataset, resource, column information.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset_name (str): Name of the dataset.\n",
    "    - resource_name (str): Name of the resource.\n",
    "    - column_name (str): Name of the column.\n",
    "    - excerpt (str): Examples or excerpt of the column.\n",
    "    - hxl_tag (str, optional): HXL tags for the column. Default is None.\n",
    "    - add_response (bool, optional): Whether to include the response in the prompt. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the prompt and optional completion/response.\n",
    "    \"\"\"\n",
    "    resource_name = resource_name.replace(f\"{LOCAL_DATA_DIR}/\",'')\n",
    "    #column_details = f\"dataset_name:'{dataset_name}'; resource_name='{resource_name}'; column_name:{column_name}; examples:{excerpt}\"\n",
    "    column_details = f\"resource_name='{resource_name}'; column_name:'{column_name}'; examples:{excerpt}\"\n",
    "\n",
    "    prompt = {\"prompt\": f\"What are the HXL tags for a column with these attributes? {column_details}\"}\n",
    "    if add_response:\n",
    "        prompt[\"completion\"] = f\"{hxl_tag}\"\n",
    "    return prompt\n",
    "\n",
    "def generate_chat_prompt(dataset_name, resource_name, column_name, excerpt, hxl_tag=None, add_response=True):\n",
    "    \"\"\"\n",
    "    Generate a chat (eg for GPT-3.5-Turbo) fine tuning prompt for HXL tags given dataset, resource, column information.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset_name (str): Name of the dataset.\n",
    "    - resource_name (str): Name of the resource.\n",
    "    - column_name (str): Name of the column.\n",
    "    - excerpt (str): Examples or excerpt of the column.\n",
    "    - hxl_tag (str, optional): HXL tags for the column. Default is None.\n",
    "    - add_response (bool, optional): Whether to include the response in the prompt. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the prompt and optional completion/response.\n",
    "    \"\"\"\n",
    "\n",
    "    system_message = \"\"\"\n",
    "        You are an assistant that replies with HXL tags and attributes\"\n",
    "    \"\"\"\n",
    "\n",
    "    resource_name = resource_name.replace(f\"{LOCAL_DATA_DIR}/\",'')\n",
    "    #column_details = f\"dataset_name:'{dataset_name}'; resource_name='{resource_name}'; column_name:{column_name}; examples:{excerpt}\"\n",
    "    column_details = f\"resource_name='{resource_name}'; column_name:'{column_name}'; examples:{excerpt}\"\n",
    "\n",
    "    user_prompt = f\"What are the HXL tags and attributes for a column with these details? {column_details}\"\n",
    "\n",
    "    prompt = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message}, \n",
    "            {\"role\": \"user\", \"content\": user_prompt}, \n",
    "        ]\n",
    "    }\n",
    "\n",
    "    if add_response:\n",
    "        prompt[\"messages\"].append({\"role\": \"assistant\", \"content\": hxl_tag})\n",
    "\n",
    "    #prompt = json.dumps(prompt)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def generate_prompts(df, \n",
    "                     heading_col='Text header', \n",
    "                     resource_name_col='File', \\\n",
    "                     tag_col='Hashtag with Attributes', \\\n",
    "                     excerpt_col='Data excerpt', \\\n",
    "                     hxl_tag=False,\n",
    "                     prompt_type='completion'):\n",
    "    \"\"\"\n",
    "    Generate a set of prompts for HXL tags from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Input DataFrame containing dataset, resource, column information.\n",
    "    - hxl_tag (bool, optional): Whether to include HXL tags in the prompts. Default is False.\n",
    "    - completion_prompt (string): One of 'completion', 'chat'\n",
    "\n",
    "    Returns:\n",
    "    - str: A string containing JSON-formatted prompts.\n",
    "    \"\"\"\n",
    "    allowed_prompt_types =  ['completion', 'chat']\n",
    "    if prompt_type not in allowed_prompt_types:\n",
    "        print(f\"Prompt type {prompt_type} is not one of {allowed_prompt_types}!\")\n",
    "        sys.exit()\n",
    "\n",
    "    prompts = []\n",
    "    for index, row in df.iterrows():\n",
    "        if prompt_type == 'completion':\n",
    "            prompt = generate_completion_prompt('',  # Dataset name\n",
    "                                    row[resource_name_col], \\\n",
    "                                    row[heading_col], \\\n",
    "                                    row[excerpt_col], \\\n",
    "                                    hxl_tag=row[tag_col], \\\n",
    "                                    add_response=True)\n",
    "        elif prompt_type == 'chat':\n",
    "            prompt = generate_chat_prompt('',  # Dataset name\n",
    "                        row[resource_name_col], \\\n",
    "                        row[heading_col], \\\n",
    "                        row[excerpt_col], \\\n",
    "                        hxl_tag=row[tag_col], \\\n",
    "                        add_response=True)\n",
    "\n",
    "        prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "def save_prompts(prompts, filename):\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        for prompt in prompts:\n",
    "            f.write(json.dumps(prompt) + \"\\n\")\n",
    "\n",
    "    print(f\"Prompts written to {filename}\")\n",
    "\n",
    "# Prompt for use with davinci-002\n",
    "#completion_prompts = generate_prompts(X_train, hxl_tag=False, prompt_type='completion')\n",
    "#save_prompts(completion_prompts, \"./data/hxl_completion_prompts.jsonl\")\n",
    "\n",
    "\n",
    "# Prompt for use with GPT-3.5-Turbo or GPT-4o-mini\n",
    "chat_prompts = generate_prompts(X_train, hxl_tag=True, prompt_type='chat')\n",
    "save_prompts(chat_prompts, \"./data/hxl_chat_prompts.jsonl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(train_file, model_name=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Fine-tune an OpenAI model using training data.\n",
    "\n",
    "    Args:\n",
    "        prompt_file (str): The file containing the prompts to use for fine-tuning.\n",
    "        model_name (str): The name of the model to fine-tune. Default is \"davinci-002\".\n",
    "\n",
    "    Returns:\n",
    "        str: The ID of the fine-tuned model.\n",
    "    \"\"\"\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    # Create a file on OpenAI for fine-tuning\n",
    "    file = client.files.create(\n",
    "        file=open(train_file, \"rb\"),\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "    file_id = file.id\n",
    "    print(f\"Uploaded training file with ID: {file_id}\")\n",
    "\n",
    "    # Start the fine-tuning job\n",
    "    ft = client.fine_tuning.jobs.create(\n",
    "        training_file=file_id,\n",
    "        model=model_name\n",
    "    )\n",
    "    ft_id = ft.id\n",
    "    print(f\"Fine-tuning job started with ID: {ft_id}\")\n",
    "\n",
    "    # Monitor the status of the fine-tuning job\n",
    "    ft_result = client.fine_tuning.jobs.retrieve(ft_id)\n",
    "    while ft_result.status != 'succeeded':\n",
    "        print(f\"Current status: {ft_result.status}\")\n",
    "        time.sleep(120)  # Wait for 60 seconds before checking again\n",
    "        ft_result = client.fine_tuning.jobs.retrieve(ft_id)\n",
    "        if 'failed' in ft_result.status.lower():\n",
    "            sys.exit()\n",
    "\n",
    "    print(f\"Fine-tuning job {ft_id} succeeded!\")\n",
    "\n",
    "    # Retrieve the fine-tuned model\n",
    "    fine_tuned_model = ft_result.fine_tuned_model\n",
    "    print(f\"Fine-tuned model: {fine_tuned_model}\")\n",
    "\n",
    "    return fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded training file with ID: file-GXG4Mo5hjlTMBQJZk38fNRFH\n",
      "Fine-tuning job started with ID: ftjob-qRoWHtzzYA4yZqNZh0OGGkyd\n",
      "Current status: validating_files\n",
      "Current status: validating_files\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n"
     ]
    }
   ],
   "source": [
    "fine_tune_model('./data/hxl_chat_prompts.jsonl', model_name=\"gpt-4o-mini-2024-07-18-alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hxl-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
